# CHIMERA AUTARCH v2.2 - Badass Features ğŸš€

## What's New: Real-Time Event Streaming & Grafana Integration

This release adds **production-grade observability** and **real-time event broadcasting** to CHIMERA AUTARCH, making it even more badass for distributed AI orchestration.

---

## ğŸ”¥ Feature 1: Real-Time Event Streaming

### Overview
WebSocket-based pub/sub event broker that broadcasts system events to all connected clients in real-time. Monitor evolutions, node changes, tool executions, and confidence updates as they happen.

### Architecture

**EventBroker Class** (`event_broker.py`)
- Centralized event publishing with priority queues
- Supports 10 event types (evolutions, nodes, tools, tasks, alerts)
- Maintains event history (configurable, default: 1000 events)
- Non-blocking async broadcast to all subscribers
- Automatic cleanup of failed subscribers

**EventStream Class**
- Per-client event stream management
- Subscription lifecycle handling
- Queue-based buffering (max 100 events per client)
- Automatic JSON serialization

**Event Types:**
```python
EventType.EVOLUTION_APPLIED      # Priority: 8
EventType.NODE_REGISTERED        # Priority: 5
EventType.NODE_DISCONNECTED      # Priority: 5
EventType.TOOL_EXECUTED          # Priority: 3
EventType.CONFIDENCE_CHANGED     # Priority: 7
EventType.LEARNING_STARTED       # Priority: 6
EventType.LEARNING_COMPLETED     # Priority: 6
EventType.TASK_DISPATCHED        # Priority: 4
EventType.TASK_COMPLETED         # Priority: 4
EventType.SYSTEM_ALERT           # Priority: 10
```

### Usage

#### 1. Subscribe to Events (WebSocket)

**Connect and subscribe:**
```python
import websockets
import json

async with websockets.connect("ws://localhost:3000") as ws:
    # Subscribe to all events
    await ws.send(json.dumps({
        "type": "subscribe_events",
        "client_id": "my_monitor",
        "event_type": "*"  # Or specific: "evolution_applied"
    }))
    
    # Receive confirmation
    response = await ws.recv()
    print(response)  # {"type": "subscribed", "client_id": "my_monitor", ...}
    
    # Stream events
    async for message in ws:
        data = json.loads(message)
        if data["type"] == "event":
            event = data["event"]
            print(f"{event['type']}: {event['data']}")
```

#### 2. Use the Demo Client

```bash
# Monitor all events
python event_stream_demo.py

# Monitor specific events
python event_stream_demo.py --event-type evolution_applied

# Use SSL
python event_stream_demo.py --ssl --host myserver.com
```

**Demo client features:**
- âœ… Color-coded event display
- âœ… Event-specific formatting (evolutions, nodes, tools)
- âœ… Priority indicators
- âœ… Timestamp formatting
- âœ… Graceful connection handling

#### 3. HTTP Event Stats

```bash
# Get event broker statistics
curl http://localhost:3000/api/events

# Response:
{
  "total_events": 1523,
  "events_by_type": {
    "evolution_applied": 45,
    "tool_executed": 892,
    "confidence_changed": 34,
    ...
  },
  "active_subscribers": 3,
  "history_size": 1000,
  "recent_events": [...]
}
```

### Integration Points

Events are automatically emitted at:
- âœ… **Evolution logging** - `persistence.log_evolution()`
- âœ… **Node registration** - `handle_message("register")`
- âœ… **Tool execution** - `dispatch_task()` success/failure
- âœ… **Confidence changes** - `record_outcome()` when delta > 0.01
- âœ… **Task dispatch/completion** - Full task lifecycle

### Performance
- Non-blocking event publishing (< 1ms per event)
- Async queue-based delivery (no slowdowns from slow subscribers)
- Automatic cleanup of disconnected clients
- Configurable history size (prevents memory bloat)

---

## ğŸ“Š Feature 2: Grafana Dashboard

### Overview
Pre-built Grafana dashboard (`grafana_dashboard.json`) with 9 panels for complete system observability.

### Dashboard Panels

1. **System Confidence Gauge** 
   - Real-time overall confidence score (0-100%)
   - Color-coded thresholds: Red < 60%, Yellow 60-80%, Green > 80%

2. **Active Nodes Over Time**
   - Timeseries graph of node count
   - Shows scaling patterns

3. **Registered Tools Count**
   - Simple stat panel showing tool inventory

4. **Tool Success Rates**
   - Multi-line timeseries for each tool
   - Tracks success percentage (0-100%)

5. **Tool Average Latency**
   - Performance monitoring per tool
   - Color-coded: Green < 0.5s, Yellow < 1s, Red > 1s

6. **Topic Confidence Scores**
   - Smooth gradient heatmap of all topics
   - Shows learning progress over time

7. **Node Reputation Distribution**
   - Donut chart of node reputation scores
   - Identifies high/low performers

8. **Node Heartbeat Status**
   - Table view of last heartbeat times
   - Alert on nodes > 60s since last contact

9. **Failure Rate by Topic**
   - Bar chart of failure rates (5min average)
   - Identifies problem areas requiring attention

### Setup

**1. Configure Prometheus to scrape CHIMERA:**
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'chimera'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:3000']
    metrics_path: '/metrics/prometheus'
```

**2. Import dashboard to Grafana:**
```bash
# Via UI: Import > Upload JSON file > Select grafana_dashboard.json

# Via API:
curl -X POST http://localhost:3000/api/dashboards/db \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d @grafana_dashboard.json
```

**3. Configure datasource:**
- Add Prometheus datasource in Grafana
- Set URL to your Prometheus instance
- Test connection

### Auto-Refresh
Dashboard refreshes every **5 seconds** by default for near-real-time monitoring.

---

## ğŸ¯ Feature 3: Enhanced Metrics Endpoint

### New HTTP Endpoints

#### `GET /api/events` - Event Broker Stats
Returns event statistics and recent event history.

**Response:**
```json
{
  "total_events": 1523,
  "events_by_type": {
    "evolution_applied": 45,
    "tool_executed": 892,
    "confidence_changed": 34
  },
  "active_subscribers": 3,
  "history_size": 1000,
  "subscriber_breakdown": {
    "*": 2,
    "evolution_applied": 1
  },
  "recent_events": [
    {
      "type": "tool_executed",
      "timestamp": 1699834567.123,
      "priority": 3,
      "data_keys": ["tool", "success", "latency"]
    }
  ]
}
```

---

## ğŸš€ Quick Start Guide

### 1. Start CHIMERA with Event Streaming

```bash
# Ensure event_broker.py is present
ls event_broker.py

# Start CHIMERA (event broker auto-loads)
python chimera_autarch.py

# You should see:
# [CHIMERA] Event broker enabled - real-time streaming active
```

### 2. Monitor Events in Real-Time

```bash
# Terminal 1: Start CHIMERA
python chimera_autarch.py

# Terminal 2: Monitor events
python event_stream_demo.py

# Terminal 3: Trigger some events
python ws_client.py
> show system stats
> read file requirements.txt
```

### 3. Set Up Grafana

```bash
# Install Prometheus (if not already)
docker run -d -p 9090:3000 \
  -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \
  prom/prometheus

# Install Grafana (if not already)
docker run -d -p 3000:3000 grafana/grafana

# Import dashboard
# Visit http://localhost:3000
# Import grafana_dashboard.json
```

---

## ğŸ“ˆ Use Cases

### Real-Time Monitoring
- **Operations team**: Watch system health in Grafana
- **Developers**: Monitor event stream during debugging
- **ML engineers**: Track confidence evolution patterns

### Alerting
- Set up Grafana alerts on low confidence
- Alert on node disconnections
- Notify on high failure rates

### Analytics
- Export event history for post-mortem analysis
- Correlate tool performance with confidence changes
- Identify bottlenecks via latency metrics

---

## ğŸ”§ Configuration

### Environment Variables
```bash
# Enable/disable event broker
export CHIMERA_ENABLE_EVENT_BROKER=true

# Event history size
export CHIMERA_EVENT_HISTORY_SIZE=1000

# Max subscribers per event type
export CHIMERA_MAX_EVENT_SUBSCRIBERS=100
```

### Code Configuration
```python
# In chimera_autarch.py
event_broker = EventBroker(
    max_history=2000  # Increase history retention
)
```

---

## ğŸ› ï¸ Development

### Adding Custom Events

```python
# In your tool implementation
async def _tool_custom(self):
    # Emit custom event
    if self.event_broker:
        await self.event_broker.publish(Event(
            type=EventType.SYSTEM_ALERT,
            data={
                "level": "info",
                "message": "Custom tool executed",
                "context": {"foo": "bar"}
            },
            priority=5
        ))
```

### Extending Event Types

```python
# In event_broker.py
class EventType(Enum):
    # ... existing types ...
    CUSTOM_EVENT = "custom_event"  # Add new type
```

---

## ğŸ“Š Metrics Reference

### Prometheus Metrics Exposed

**System Metrics:**
- `chimera_node_count` - Number of registered nodes
- `chimera_system_confidence` - Overall system confidence (0-1)

**Node Metrics:**
- `chimera_node_reputation{node_id, type}` - Node reputation score (0-1)
- `chimera_node_last_heartbeat_seconds{node_id}` - Time since last heartbeat

**Tool Metrics:**
- `chimera_tool_success_rate{tool, version}` - Tool success rate (0-1)
- `chimera_tool_avg_latency_seconds{tool}` - Average execution latency

**Topic Metrics:**
- `chimera_topic_confidence{topic}` - Topic-specific confidence (0-1)
- `chimera_topic_failure_count{topic}` - Total failures per topic

---

## ğŸ“ Advanced Features

### Event Filtering

Subscribe to specific events only:
```python
# Subscribe to evolution events only
await ws.send(json.dumps({
    "type": "subscribe_events",
    "event_type": "evolution_applied"
}))
```

### Event History Replay

```bash
# Get last 100 events via HTTP
curl http://localhost:3000/api/events | jq '.recent_events'
```

### Multi-Client Broadcasting

All subscribers receive the same events simultaneously:
- Client A subscribes to "*" (all events)
- Client B subscribes to "evolution_applied"
- When evolution occurs:
  - Client A receives the event
  - Client B receives the event
  - Both get identical data

---

## ğŸ› Troubleshooting

### Event Stream Not Working

```bash
# Check if event broker is enabled
curl http://localhost:3000/api/events

# Should NOT return: {"error": "Event broker not available"}

# Check logs for:
# [CHIMERA] Event broker enabled - real-time streaming active
```

### No Events Appearing

```bash
# Verify subscription
# In event_stream_demo.py output, look for:
# âœ“ Subscribed to events: *

# Trigger test event
python ws_client.py
> show system stats  # This should emit tool_executed events
```

### Grafana Dashboard Empty

```bash
# Verify Prometheus is scraping
curl http://localhost:3000/api/v1/targets

# Check Prometheus metrics endpoint
curl http://localhost:3000/metrics/prometheus
```

---

## ğŸ“ Summary

**New Files:**
- `event_broker.py` - Event pub/sub system (322 lines)
- `event_stream_demo.py` - Real-time event monitor client (262 lines)
- `grafana_dashboard.json` - Pre-built Grafana dashboard (518 lines)

**Modified Files:**
- `chimera_autarch.py` - Integrated event broker (+150 lines)
  - Added event emissions at key points
  - New `/api/events` endpoint
  - WebSocket `subscribe_events` message type

**New Capabilities:**
- âœ… Real-time event streaming to unlimited subscribers
- âœ… 10 event types with priority levels
- âœ… Event history and statistics
- âœ… Production-ready Grafana dashboard
- âœ… Enhanced monitoring and alerting

**Backward Compatibility:**
- âœ… System works without event_broker.py (graceful degradation)
- âœ… Existing functionality unchanged
- âœ… All tests still pass

---

## ğŸš§ Future Enhancements (Still Badass)

**Planned for v2.3:**
1. **LLM Integration** - Replace placeholder code generation with real AI
2. **Task Queue System** - Priority-based distributed task scheduling
3. **JWT Authentication** - Secure WebSocket connections with RBAC
4. **GraphQL Subscriptions** - Real-time GraphQL over WebSockets
5. **OpenTelemetry Tracing** - Distributed tracing for complex workflows

---

**Version:** CHIMERA AUTARCH v2.2  
**Release Date:** 2025-11-12  
**Compatibility:** Python 3.12+  
**License:** MIT  

*Making AI orchestration even more badass, one feature at a time.* ğŸ”¥
